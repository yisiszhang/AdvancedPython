{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Precept2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOETtUv+fbQY1P2enaJZ3jJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yisiszhang/AdvancedPython/blob/main/Precept2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fEvsmWo9wh6"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KsBuZGi95bQ"
      },
      "source": [
        "# let's explore the digit data\n",
        "# each data (0-9) is a 8x8=64 dimension image\n",
        "digit = datasets.load_digits()\n",
        "X = digit.data\n",
        "y = digit.target\n",
        "\n",
        "print(X.shape)\n",
        "print(y[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfcklzwA98Jw"
      },
      "source": [
        "# PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnECBVfe99QT"
      },
      "source": [
        "# explore the data\n",
        "# PCA\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "#pca = \n",
        "\n",
        "# plot the first 2 PCs in the PC space\n",
        "# pc = \n",
        "\n",
        "plt.scatter(pc[:,0],pc[:,1],c=y)\n",
        "plt.xlabel('pc1')\n",
        "plt.ylabel('pc2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRCXCaS-WjY"
      },
      "source": [
        "# how many PCs are enough to describe the data (we usually use >95% cumulative explained variance)?\n",
        "\n",
        "# var_explained = \n",
        "\n",
        "# calculate cumulative variance explained\n",
        "cumsum = np.cumsum(var_explained)\n",
        "\n",
        "# plot cumulative explained variance vs # PC\n",
        "plt.plot(np.arange(1,len(cumsum)+1), cumsum)\n",
        "plt.xlabel('#PC')\n",
        "plt.ylabel('variance explained')\n",
        "plt.show()\n",
        "\n",
        "# print # PCs to include\n",
        "d = np.argmax(cumsum >= 0.95) + 1\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-zM7f0S-wI4"
      },
      "source": [
        "# K-means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVmyLn4u-xrk"
      },
      "source": [
        "# cluster data using k-means\n",
        "# determine k to use using silhouette score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "sil = []\n",
        "kmax = 20\n",
        "for k in range(2, kmax+1):\n",
        "  #kmeans = \n",
        "  #labels = \n",
        "  sil.append(silhouette_score(X, labels, metric='euclidean'))\n",
        "\n",
        "# plot silouette vs k\n",
        "plt.plot(np.arange(2,kmax+1), sil, 'o-')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('silhouette')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# determine k\n",
        "best_k = sil.index(max(sil)) + 2\n",
        "print(best_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlPY2WIQ_NaG"
      },
      "source": [
        "# visualize kmeans result using the best k in first 2 PCs\n",
        "#kmeans = \n",
        "\n",
        "plt.scatter(pc[:,0], pc[:,1], c=kmeans.labels_)\n",
        "plt.xlabel('pc1')\n",
        "plt.ylabel('pc2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeY-wI3v_TOz"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsmE0197_Utt"
      },
      "source": [
        "# split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "# test_ratio = \n",
        "# X_train, X_test, y_train, y_test = \n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0TeaMMh_f2G"
      },
      "source": [
        "# compare logistic regression vs LDA performance in predicting labels\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# train a logistic regression model\n",
        "#lr_clf = \n",
        "# train a LDA model\n",
        "#lda_clf = \n",
        "\n",
        "# print accuracy\n",
        "# predict using logistic regression\n",
        "#y_pred_lr = \n",
        "# predict using LDA\n",
        "#y_pred_lda = \n",
        "print('Logistic regression accuracy: %f' % accuracy_score(y_test, y_pred_lr))\n",
        "print('LDA accuracy: %f' % accuracy_score(y_test, y_pred_lda))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJZA7cLZ_8HH"
      },
      "source": [
        "# train a linear SVC and use cross-validation to determine C\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# split training set into nfolds\n",
        "#nfolds = \n",
        "#skf = \n",
        "\n",
        "# C to try\n",
        "Cs = np.logspace(-5, 1, 20)\n",
        "# store the accuracy scores for each C\n",
        "scores = np.zeros(len(Cs))\n",
        "\n",
        "# initialze a linear svc model\n",
        "#clf = \n",
        "i = 0\n",
        "for C in Cs:\n",
        "  score = []\n",
        "  clf.set_params(C=C)\n",
        "  for train, test in skf.split(X_train, y_train):\n",
        "    # fit the model for each training fold\n",
        "\n",
        "    # predict using test fold\n",
        "    \n",
        "    # append the score for each test fold\n",
        "    \n",
        "  scores[i] = (np.array(score)).mean()\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtFDVfZWA15e"
      },
      "source": [
        "# cross_val_score funtion is very handy. You should understand this is doing the same thing as above\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cs = np.logspace(-5, 1, 20)\n",
        "scores = np.zeros(len(Cs))\n",
        "clf = LinearSVC(random_state=0)\n",
        "i = 0\n",
        "for C in Cs:\n",
        "  clf.set_params(C=C)\n",
        "  score = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
        "  scores[i] = score.mean()\n",
        "  i += 1\n",
        "\n",
        "# print the best C\n",
        "best_C = Cs[np.argmax(scores)]\n",
        "print(best_C)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COIK3m4qBJ9h"
      },
      "source": [
        "# report the final test accuracy\n",
        "# print the best C\n",
        "#best_C = \n",
        "print(best_C)  \n",
        "\n",
        "# report the test accuracy score using the selected C\n",
        "\n",
        "\n",
        "\n",
        "print('Linear SVC accuracy: %f' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
